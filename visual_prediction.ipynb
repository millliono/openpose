{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coco_dataset\n",
    "import pathlib\n",
    "import show_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import model\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (368, 368)\n",
    "targ_size = (46, 46)\n",
    "coco_dataset = coco_dataset.CocoKeypoints(\n",
    "    root=str(pathlib.Path(\"../coco\") / \"images\" / \"train2017\"),\n",
    "    annFile=str(pathlib.Path(\"../coco\") / \"annotations\" / \"annotations\" / \"person_keypoints_train2017.json\"),\n",
    "    input_transform=transforms.Compose([\n",
    "        transforms.Resize(inp_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float32),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]),\n",
    "    targ_size=targ_size)\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    device = \"cuda:0\"\n",
    "    model = torch.nn.DataParallel(model.openpose(), device_ids=[0])\n",
    "    model.load_state_dict(torch.load(\"save_modelGG.pth\"))\n",
    "    model.eval()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = coco_dataset[i]\n",
    "\n",
    "input_image, pafs, heatmaps, mask_out, keypoints, image, target = sample\n",
    "show_utils.show_coco(image, target, coco_dataset.coco, draw_bbox=False)\n",
    "\n",
    "input_image.unsqueeze_(0)\n",
    "pred_pafs, pred_heatmaps, _, _ = model(input_image.to(device))  \n",
    "\n",
    "pred_pafs.squeeze_(0)\n",
    "pred_heatmaps.squeeze_(0)\n",
    "print(f\"sample: {i}\")\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import post\n",
    "image_size = image.size\n",
    "\n",
    "with torch.no_grad():\n",
    "    kpt_groups = post.post_process(pred_heatmaps.cpu(), pred_pafs.cpu())\n",
    "if kpt_groups:\n",
    "    keypoints_post = post.coco_format(kpt_groups, image_size)\n",
    "    show_utils.draw_keypoints(image,keypoints_post, connectivity=common.connect_skeleton, keypoint_color=\"orange\", line_color=\"magenta\")\n",
    "else:\n",
    "    print(\"NO DETECTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# with torch.no_grad():\n",
    "\n",
    "    # show_utils.show_heatmaps_combined(pred_heatmaps.cpu())\n",
    "\n",
    "    # show_utils.show_heatmaps(pred_heatmaps.cpu())\n",
    "\n",
    "    # show_utils.show_pafs(pred_pafs.cpu())\n",
    "\n",
    "    # show_utils.show_pafs_quiver(pred_pafs.cpu(), keypoints, size=targ_size)\n",
    "\n",
    "    # plt.figure()\n",
    "    # show_utils.show_pafs_quiver_combined(pred_pafs.cpu(), size=targ_size)\n",
    "\n",
    "    # show_utils.show_tensors(mask_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
