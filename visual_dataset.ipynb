{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coco_dataset\n",
    "import pathlib\n",
    "import show_utils\n",
    "import common\n",
    "import numpy as np\n",
    "import copy\n",
    "from torchvision.transforms import v2\n",
    "import transforms as mytf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (368, 368)\n",
    "targ_size = (46, 46)\n",
    "coco_dataset = coco_dataset.CocoKeypoints(\n",
    "    root=str(pathlib.Path(\"../coco\") / \"images\" / \"train2017\"),\n",
    "    annFile=str(pathlib.Path(\"../coco\") / \"annotations\" / \"annotations\" / \"person_keypoints_train2017.json\"),\n",
    "    transform=v2.Compose([mytf.RandomCrop(0.8), mytf.Resize(368),\n",
    "                          mytf.Pad(368)]),\n",
    "    targ_size=targ_size)\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_image, pafs, heatmaps, image, paf_locs, target = coco_dataset[i]  # ,mask_out\n",
    "\n",
    "show_utils.show_coco(image, target, coco_dataset.coco, draw_bbox=False)\n",
    "\n",
    "print(f\"sample: {i}\")\n",
    "print(image.size)\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import post\n",
    "tf_image = v2.ToPILImage()(tf_image)\n",
    "\n",
    "kpt_groups = post.post_process(heatmaps, pafs, tf_image.size)\n",
    "\n",
    "if kpt_groups:\n",
    "    keypoints_post = post.coco_format(kpt_groups)\n",
    "    show_utils.draw_keypoints(copy.deepcopy(tf_image), keypoints_post, connectivity=common.connect_skeleton, keypoint_color=\"orange\", line_color=\"magenta\")\n",
    "else:\n",
    "    print(\"NO DETECTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps = heatmaps.numpy()\n",
    "pafs = pafs.numpy()\n",
    "paf_locs = np.array(paf_locs, dtype=float)\n",
    "\n",
    "# mask_out = mask_out.squeeze_(0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #---------heatmaps---------\n",
    "# print(f\"Heatmaps.size = {heatmaps.shape}\")\n",
    "# show_utils.plot_grid(heatmaps, 2, 10, (17,4))\n",
    "\n",
    "# #---------pafs---------\n",
    "# print(f\"Pafs.size = {pafs.shape}\")\n",
    "# show_utils.plot_grid(pafs[[x for x in range(len(pafs)) if x%2==0]], 1, 17, (17, 2))\n",
    "# show_utils.plot_grid(pafs[[x for x in range(len(pafs)) if x%2==1]], 1, 17, (17, 2))\n",
    "\n",
    "# # ---------blend---------\n",
    "# show_utils.blend(heatmaps, tf_image, rows=7, cols=3, figsize=(15, 30))\n",
    "# show_utils.blend(paf_locs, tf_image, rows=6, cols=3, figsize=(15, 30))\n",
    "# show_utils.blend([mask_out], tf_image, rows=1, cols=2, figsize=(12, 4))\n",
    "\n",
    "#---------surface---------\n",
    "# show_utils.surface(heatmaps[5])\n",
    "\n",
    "#---------quiver---------\n",
    "# show_utils.pafs_quiver_combined(pafs, size=targ_size)\n",
    "# show_utils.pafs_quiver(pafs, size=targ_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
